{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISHZtJd1ffdH"
   },
   "source": [
    "# <center> MUSIC INFORMATION RETRIEVAL</center>\n",
    "## <center> üéº Audio chord estimation - with Madmom</center>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: *this notebook was prepared by **Andrea Poltronieri**.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4DHyY3KfyMn"
   },
   "source": [
    "Madmom is an audio signal processing library written in Python with a strong focus on music information retrieval (MIR) tasks.\n",
    "\n",
    "It includes pretrained models for chord estimation, among other things.\n",
    "The ACE models implemented in malmon were originally proposed in the [paper](https://archives.ismir.net/ismir2016/paper/000178.pdf):\n",
    "```\n",
    "Filip Korzeniowski and Gerhard Widmer, ‚ÄúFeature Learning for Chord Recognition: The Deep Chroma Extractor‚Äù, Proceedings of the 17th International Society for Music Information Retrieval Conference (ISMIR), 2016.\n",
    "```\n",
    "In this notebook, we show how to use Madmom to estimate the chords of the audio files in the dataset and how to evaluate the performance of the models implemented in the library.\n",
    "\n",
    "For more information about Madmom, please visit the [official website](https://madmom.readthedocs.io/en/v0.16.1/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to run the notebook\n",
    "You can download the notebook and run it locally in your computer.\n",
    "\n",
    "You can also run it in Google Colab by using the following link.\n",
    "\n",
    "<table align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/mrocamora/mir_course/blob/main/notebooks/MIR_course-audio_chord_estimation_with_madmom.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dH1AaovHf4rH"
   },
   "source": [
    "## ü™õ Setup and installation\n",
    "\n",
    "Madmom has some compatibility issues, mainly related to the\n",
    "numpy/scipy version.\n",
    "This notebook is tested with python `3.10.12` and madmom `0.16.1`. If you have any issues,\n",
    "please make sure you have the correct version of madmom and numpy installed.\n",
    "\n",
    "Furthermore, in this notebook, a number of tricks are implemented in order to be able to use madmom in Python 3.10, i.e. the version of Python currently distributed in Google Colab.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ba91i0SOZzxp",
    "outputId": "e2bfac23-df39-422d-e811-9087e760212d"
   },
   "outputs": [],
   "source": [
    "# python version check\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNZi2H82ezXE"
   },
   "source": [
    "**!!!Session restart required after installing libraries!!!**\n",
    "\n",
    "Please click on `RESTART SESSION` once the installation process has finished in order to make numpy installation effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Ls7ihdpwC9M",
    "outputId": "d62a4f35-7828-45e1-fd4c-2dbcdcd482d5"
   },
   "outputs": [],
   "source": [
    "# install libraries\n",
    "!pip install numpy==1.23.5\n",
    "!pip install madmom==0.16.1\n",
    "!pip install mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWo38djDxnJc"
   },
   "outputs": [],
   "source": [
    "#replace some source code in order to make it usable in python 3.10\n",
    "!sed -i \"s/from collections import/from collections.abc import/\" /usr/local/lib/python3.10/dist-packages/madmom/processors.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxDxxnHHfxRZ"
   },
   "source": [
    "## üíΩ Load audio files\n",
    "The script loads any audio files uploaded in the main directory of Google Colab having the following extensions: `.wav`, `.mp3`, `.mp4`, `.flac`.\n",
    "\n",
    "If more audio files are uploaded, given the showcase purpose of this notebook, only one will be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** *The following cell is needed to download example audio files.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download audio file\n",
    "wget.download('https://github.com/mrocamora/mir_course/blob/main/audio/LetItBe.mp3?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "up12dLbohx2f"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yk2YmIumgvmZ",
    "outputId": "109004a9-4085-4b39-e978-39c7c7fb8f5b"
   },
   "outputs": [],
   "source": [
    "audio_extensions = [\".mp3\", \".mp4\" \".wav\", \".flac\"]\n",
    "audio_files = [file for file in os.listdir('./') if file.endswith(tuple(audio_extensions))]\n",
    "\n",
    "assert len(audio_files) > 0, \"No audio files uploaded in the main `content` folder.\"\n",
    "\n",
    "file_path = audio_files[0]\n",
    "f\"Processing audio file: {file_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwc2u0lgfffV"
   },
   "source": [
    "## 1 Chord recognition from Deep Chroma Features\n",
    "\n",
    "Recognise major and minor chords from deep chroma vectors using a Conditional Random Field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "640XWrz_wwZ1"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from madmom.audio.chroma import DeepChromaProcessor  # type: ignore\n",
    "from madmom.features.chords import DeepChromaChordRecognitionProcessor  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKTC9hPzypVG"
   },
   "outputs": [],
   "source": [
    "# initialise the DeepChromaProcessor to extract the chroma vectors from audio\n",
    "dcp = DeepChromaProcessor()\n",
    "# create a DeepChromaChordRecognitionProcessor to decode a chord sequence from the extracted chromas\n",
    "decode = DeepChromaChordRecognitionProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0A5YcmmhbW-4",
    "outputId": "952a361b-e448-4fa6-ed29-d19bbdb859fb"
   },
   "outputs": [],
   "source": [
    "# get chord predictions\n",
    "chroma = dcp(file_path)\n",
    "decode(chroma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E909ZH0nstLE"
   },
   "source": [
    "## 2 Chord recognition from learned features\n",
    "\n",
    "Recognise major and minor chords from learned features extracted by a convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjEkvF7DcCm3"
   },
   "outputs": [],
   "source": [
    "from madmom.features.chords import CNNChordFeatureProcessor, CRFChordRecognitionProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zg-puvpcApo"
   },
   "outputs": [],
   "source": [
    "featproc = CNNChordFeatureProcessor()\n",
    "crf_decode = CRFChordRecognitionProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vwP2GGZcuWW",
    "outputId": "f1f118bf-298f-43fd-e290-88097cbe05ad"
   },
   "outputs": [],
   "source": [
    "feats = featproc('LetItBe.mp3')\n",
    "crf_decode(feats)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
